{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "x00t_uJCEbeb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "#@title Setup Environment\n",
    "# Install the latest Tensorflow version.\n",
    "!pip install -q tensorflow-text\n",
    "!pip install annoy\n",
    "!pip install simpleneighbors[annoy]\n",
    "# !pip install -q nltk\n",
    "# !pip install -q tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import os\n",
    "import pprint\n",
    "import simpleneighbors\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow_text import SentencepieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "DmeFAuVsyWxg",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package punkt to /home/sandipan/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
    }
   ],
   "source": [
    "\n",
    "nltk.download('punkt')\n",
    "questions = []\n",
    "# Create the global index object\n",
    "index = simpleneighbors.SimpleNeighbors(512, metric='angular')\n",
    "\n",
    "def load_data(path='../data/faq.csv', sep=\"##,##\"):\n",
    "    print('Loading data....')\n",
    "    data = pd.read_csv(path,sep='##,##')\n",
    "    print('...... done')\n",
    "    return data\n",
    "\n",
    "def extract_sentences_from_answer(df):\n",
    "  all_sentences = []\n",
    "  for index, row in df.iterrows():\n",
    "      # nltk.tokenize.sent_tokenize is a unsupervised algo\n",
    "      sentences = nltk.tokenize.sent_tokenize(row['answer'])    \n",
    "      sentences = sentences + nltk.tokenize.sent_tokenize(row['question'])\n",
    "      all_sentences.extend(zip(sentences, [row['answer']] * len(sentences)))\n",
    "  return list(set(all_sentences)) # remove duplicates\n",
    "\n",
    "def extract_questions(df):  \n",
    "  for index, row in df.iterrows():\n",
    "    questions.append((row['question'], row['answer']))   \n",
    "  return list(set(questions))\n",
    "        \n",
    "\n",
    "def get_nearest(query_text):\n",
    "  query_embedding = model.signatures['question_encoder'](tf.constant([query_text]))['outputs'][0]\n",
    "  search_results = index.nearest(query_embedding, n=num_results)\n",
    "  return search_results\n",
    "\n",
    "def load_USE_model(path='/home/sandipan/projects/model/'):  \n",
    "  print('Loading Universal Sentence Encoder from', path)\n",
    "  m = hub.load(path)\n",
    "  print('Universal Sentence Encoder model from in mem', m)\n",
    "  return m\n",
    "\n",
    "def build_search_index(data, model, batch_size = 10, index_path='/home/sandipan/projects/index/faq.ann'):\n",
    "  sentences = extract_sentences_from_answer(data)\n",
    "  encodings = model.signatures['response_encoder'](\n",
    "    input=tf.constant([sentences[0][0]]),\n",
    "    context=tf.constant([sentences[0][1]]))\n",
    "  print('Computing embeddings for %s sentences' % len(sentences))\n",
    "  slices = zip(*(iter(sentences),) * batch_size)\n",
    "  num_batches = int(len(sentences) / batch_size)\n",
    "  print('Batch wise index add...')\n",
    "  for s in tqdm(slices, total=num_batches):\n",
    "    response_batch = list([r for r, c in s])\n",
    "    context_batch = list([c for r, c in s])\n",
    "    encodings = model.signatures['response_encoder'](\n",
    "                  input=tf.constant(response_batch),\n",
    "                  context=tf.constant(context_batch)\n",
    "                )    \n",
    "    for batch_index, batch in enumerate(response_batch):\n",
    "      index.add_one(batch, encodings['outputs'][batch_index])\n",
    "\n",
    "  print('Building Index...')\n",
    "  index.build()\n",
    "  print('Saving Index...')\n",
    "  index.save(index_path)\n",
    "  return dict(sentences)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loading data....\n...... done\n                   question                                             answer\n0            What is NEFT ?  National Electronic Funds Transfer or NEFT is ...\n1  Where is mount everest ?  Mount Everest is the highest of the Himalayan ...\nLoading Universal Sentence Encoder from /home/sandipan/projects/model/\nUniversal Sentence Encoder model from in mem <tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject object at 0x7f36bf4d2410>\nComputing embeddings for 39 sentences\nBatch wise index add...\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f53925c9321e42c1a17452e541721835"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nBuilding Index...\nSaving Index...\n"
    }
   ],
   "source": [
    "data = load_data('../data/faq.csv')\n",
    "print(data.head(2))\n",
    "model = load_USE_model('/home/sandipan/projects/model/')\n",
    "# extract_questions(data)\n",
    "sentence_dict = build_search_index(data = data,model = model, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "J0xTw2w3UViK",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "What is NEFT ? 0\nNational Electronic Funds Transfer or NEFT is an electronic funds transfer system maintained by the Reserve Bank of India. 3\nStarted in November 2005, the setup was established and maintained by Institute for Development and Research in Banking Technology 3\nwhat is the price of sari ? 0\nWhen I use Popmoney when will the recipient receive the funds? 0\nIf you are still unable to activate your card, please call us at 800-868-4262 or 919-420-8000. 0\nIt also offers functionality not found on the desktop site, such as Mobile Check Deposit and Tap Balances. 0\nThe Digital Banking mobile app contains most of the same features as the desktop site. 3\nOften times, it can take up to 3 days after accepting the payment. 3\nIf a fee is imposed, it will be deducted from the amount of the incoming wire prior to us receiving it and posting it to your account. 0\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  original_q                                             answer confidence\n0             National Electronic Funds Transfer or NEFT is ...        100\n1                                   The pink one cost about 250        100\n2             This depends on the delivery option selected b...        100\n3             Please remember to hit the pound key (\"#\") aft...        100\n4             The Digital Banking mobile app contains most o...        100\n5             While Coastal does not charge a fee for receiv...        100",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original_q</th>\n      <th>answer</th>\n      <th>confidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>National Electronic Funds Transfer or NEFT is ...</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>The pink one cost about 250</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>This depends on the delivery option selected b...</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>Please remember to hit the pound key (\"#\") aft...</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>The Digital Banking mobile app contains most o...</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>While Coastal does not charge a fee for receiv...</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "results = get_nearest('NEFT')\n",
    "ans = pd.DataFrame(columns=['original_q','answer','confidence'])    \n",
    "for result in results:\n",
    "    print(result, ans[ans['answer'] == sentence_dict[result]].size)\n",
    "    if(ans[ans['answer'] == sentence_dict[result]].size == 0):\n",
    "        values = ['',sentence_dict[result],100]\n",
    "        zipped = zip(ans.columns, values)    \n",
    "        a_dictionary = dict(zipped)\n",
    "        ans = ans.append(a_dictionary,ignore_index=True)  \n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "ans[ans['answer'] == 'The pinkss one cost about 250'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "anss = pd.DataFrame(columns=['original_q','answer','confidence']) \n",
    "anss[anss['answer'] == 'The pinkss one cost about 250'].size  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "VFMCdVJIIraw"
   ],
   "name": "Universal Encoder Q&A Model Retrieval Demo",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}